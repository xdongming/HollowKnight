{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0-qYzCR5zlG",
        "outputId": "e9c21df3-4cb8-4a51-c094-34a176283192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Suw44MRFpK0g",
        "outputId": "504ecf70-6b7d-4905-80a2-677e64df085b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: keras 2.8.0\n",
            "Uninstalling keras-2.8.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/keras-2.8.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/keras/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled keras-2.8.0\n",
            "y\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.4.3\n",
            "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.4.3) (1.5.2)\n",
            "Installing collected packages: keras\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires keras<2.9,>=2.8.0rc0, but you have keras 2.4.3 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-2.4.3\n",
            "Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.8.2+zzzcolab20220527125636.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "y\n",
            "  Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.4.1\n",
            "  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3 MB 13 kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.37.1)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 53.8 MB/s \n",
            "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 64.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 61.6 MB/s \n",
            "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 74.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.8.0)\n",
            "Collecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 57.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.2.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68719 sha256=c70fd3c6364a3dd5ec7b1d5188f89c44bb35822c0ea0527b6284d181734b1ed1\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, h5py, gast, flatbuffers, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.3\n",
            "    Uninstalling grpcio-1.46.3:\n",
            "      Successfully uninstalled grpcio-1.46.3\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.0.0\n",
            "    Uninstalling absl-py-1.0.0:\n",
            "      Successfully uninstalled absl-py-1.0.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 numpy-1.19.5 tensorflow-2.4.1 tensorflow-estimator-2.4.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu==2.4.1\n",
            "  Downloading tensorflow_gpu-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3 MB 13 kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (0.3.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.15.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.12.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.32.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (2.8.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (2.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (3.17.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (0.15.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (3.7.4.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (0.37.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.6.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.1) (1.12)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.1) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.1) (3.2.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall keras\n",
        "!pip install keras==2.4.3\n",
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==2.4.1\n",
        "!pip uninstall tensorflow-gpu\n",
        "!pip install tensorflow-gpu==2.4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeK4gSv1OCGc",
        "outputId": "69b70eb5-9502-47d1-b787-a3164f4b79d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "save model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "save model\n",
            "save model\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from random import randint\n",
        "import os\n",
        "while episode < max_episode:\n",
        "  episode += 1\n",
        "  if episode % 5 == 0:\n",
        "    model.load_target_model()\n",
        "  # while True:\n",
        "  #   with open('/content/drive/Othercomputers/我的笔记本电脑/share/command.txt', 'r') as f:\n",
        "  #     command=f.read()\n",
        "  #   if command=='1':\n",
        "  #     break\n",
        "  #   time.sleep(0.1)\n",
        "  # while True:\n",
        "  #   flag=os.path.exists('/content/drive/Othercomputers/我的笔记本电脑/share/input.npz') \n",
        "  #   if flag==True:\n",
        "  #     data=np.load('/content/drive/Othercomputers/我的笔记本电脑/share/input.npz')\n",
        "  #     break\n",
        "  #   time.sleep(0.1)\n",
        "  setm = set()\n",
        "  while len(setm)<8:\n",
        "    m = randint(0, 44)\n",
        "    setm.add(m)\n",
        "  listm = [*setm]\n",
        "\n",
        "  act_q_sum = 0\n",
        "  move_q_sum = 0\n",
        "  act_se_sum = 0\n",
        "  move_se_sum = 0\n",
        "\n",
        "  for i in listm:\n",
        "    data=np.load('/content/drive/Othercomputers/我的笔记本电脑/share/input'+str(i)+'.npz')\n",
        "    batch_station1=data['arr_0']\n",
        "    batch_actions1=data['arr_1']\n",
        "    batch_reward1=data['arr_2']\n",
        "    batch_next_station1=data['arr_3']\n",
        "    batch_done1=data['arr_4']\n",
        "    batch_station2=data['arr_5']\n",
        "    batch_actions2=data['arr_6']\n",
        "    batch_reward2=data['arr_7']\n",
        "    batch_next_station2=data['arr_8']\n",
        "    batch_done2=data['arr_9']\n",
        "    act_q, act_loss = algorithm.act_learn(batch_station2, batch_actions2, batch_reward2, batch_next_station2, batch_done2)\n",
        "    move_q, move_loss = algorithm.move_learn(batch_station1, batch_actions1, batch_reward1, batch_next_station1, batch_done1)\n",
        "    act_q_sum = act_q_sum + act_q\n",
        "    move_q_sum = move_q_sum + move_q\n",
        "    act_se_sum = act_se_sum + act_loss\n",
        "    move_se_sum = move_se_sum + move_loss\n",
        "  with open('/content/drive/Othercomputers/我的笔记本电脑/share/act_q.txt', 'a') as f:\n",
        "    f.write(str(float(act_q_sum/8))+' ')\n",
        "  with open('/content/drive/Othercomputers/我的笔记本电脑/share/act_se.txt', 'a') as f:\n",
        "    f.write(str(float(act_se_sum/8))+' ')\n",
        "  with open('/content/drive/Othercomputers/我的笔记本电脑/share/move_q.txt', 'a') as f:\n",
        "    f.write(str(float(move_q_sum/8))+' ')\n",
        "  with open('/content/drive/Othercomputers/我的笔记本电脑/share/move_se.txt', 'a') as f:\n",
        "    f.write(str(float(move_se_sum/8))+' ')\n",
        "  model.save_mode()\n",
        "  with open('/content/drive/Othercomputers/我的笔记本电脑/share/command.txt', 'w') as f:\n",
        "    f.write('0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfMqfwy6RJNd",
        "outputId": "0b263f30-37c4-46ad-d4ec-d5e99473cd6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 4, 200, 400, 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv3D)                  (None, 3, 99, 199, 3 1760        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv3D)                  (None, 2, 97, 197, 4 27696       conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv3D)                  (None, 1, 95, 195, 6 55360       conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 95, 195, 64)  0           conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 95, 195, 64)  147712      lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 48, 98, 96)   310752      sequential[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, 24, 49, 128)  565888      sequential_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "sequential_5 (Sequential)       (None, 12, 25, 256)  2098432     sequential_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "pooling (GlobalAveragePooling2D (None, 256)          0           sequential_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "a_func (Dense)                  (None, 7)            1799        pooling[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_mean (TFOpLambda (1, 1)               0           a_func[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.negative (TFOpLambda)   (1, 1)               0           tf.math.reduce_mean[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "v_func (Dense)                  (None, 1)            257         pooling[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 7)            0           a_func[0][0]                     \n",
            "                                                                 tf.math.negative[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 7)            0           v_func[0][0]                     \n",
            "                                                                 add[0][0]                        \n",
            "==================================================================================================\n",
            "Total params: 3,209,656\n",
            "Trainable params: 3,209,656\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "load action model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "load move model\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "episode=0\n",
        "max_episode=30000\n",
        "LEARNING_RATE = 0.00001  \n",
        "GAMMA = 0.8\n",
        "WIDTH = 400\n",
        "HEIGHT = 200\n",
        "ACTION_DIM = 7\n",
        "FRAMEBUFFERSIZE = 4\n",
        "INPUT_SHAPE = (FRAMEBUFFERSIZE, HEIGHT, WIDTH, 3)\n",
        "model = Model(INPUT_SHAPE, ACTION_DIM)\n",
        "#model.save_mode()\n",
        "model.load_model()\n",
        "model.load_target_model()\n",
        "algorithm = DQN(model, gamma=GAMMA, learnging_rate=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do6YJv9Q8bWI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.initializers import RandomNormal\n",
        "from tensorflow.keras.models import load_model, Model as mod\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.layers import add, Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \\\n",
        "    Activation, GlobalAveragePooling2D, Conv3D, MaxPooling3D, GlobalAveragePooling3D, Reshape, Lambda\n",
        "\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "class BasicBlock(layers.Layer):\n",
        "    def __init__(self, filter_num, name, stride=1, **kwargs):\n",
        "        super(BasicBlock, self).__init__(**kwargs)\n",
        "        self.filter_num = filter_num\n",
        "        self.stride = stride\n",
        "        self.layers = []\n",
        "        self.conv1 = layers.Conv2D(filter_num, 3, strides=stride, padding='same', name=name + '_1')\n",
        "        # self.bn1=layers.BatchNormalization()\n",
        "        self.relu = layers.Activation('relu')\n",
        "\n",
        "        self.conv2 = layers.Conv2D(filter_num, 3, strides=1, padding='same', name=name + '_2')\n",
        "        # self.bn2 = layers.BatchNormalization()\n",
        "        self.layers.append(self.conv1)\n",
        "        self.layers.append(self.conv2)\n",
        "        # self.layers.append(self.bn1)\n",
        "        # self.layers.append(self.bn2)\n",
        "        if stride != 1:\n",
        "            self.downsample = models.Sequential()\n",
        "            self.downsample.add(layers.Conv2D(filter_num, 1, strides=stride))\n",
        "            self.layers.append(self.downsample)\n",
        "        else:\n",
        "            self.downsample = lambda x: x\n",
        "\n",
        "    def get_layer(self, index):\n",
        "        return self.layers[index]\n",
        "\n",
        "    def get_layers(self):\n",
        "        return self.layers\n",
        "\n",
        "    def call(self, input, training=None):\n",
        "        out = self.conv1(input)\n",
        "        # out=self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        # out=self.bn2(out)\n",
        "\n",
        "        identity = self.downsample(input)\n",
        "        output = layers.add([out, identity])  # ***\n",
        "        output = tf.nn.relu(output)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'filter_num':\n",
        "                self.filter_num,\n",
        "            'stride':\n",
        "                self.stride\n",
        "        }\n",
        "\n",
        "        base_config = super(BasicBlock, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "class Model:\n",
        "    def __init__(self, input_shape, act_dim):\n",
        "        self.act_dim = act_dim\n",
        "        self.move_dim = 4\n",
        "        self.input_shape = input_shape\n",
        "        self._build_model()\n",
        "        self.act_loss = []\n",
        "        self.move_loss = []\n",
        "\n",
        "    def load_model(self):\n",
        "\n",
        "        # self.shared_model = load_model(\"./model/shared_model.h5\", custom_objects={'BasicBlock': BasicBlock})\n",
        "        if os.path.exists(\"/content/drive/Othercomputers/我的笔记本电脑/share/act_part.h5\"):\n",
        "            print(\"load action model\")\n",
        "            self.act_model = models.Sequential()\n",
        "            self.private_act_model = load_model(\"/content/drive/Othercomputers/我的笔记本电脑/share/act_part.h5\", custom_objects={'BasicBlock': BasicBlock})\n",
        "            # self.act_model.add(self.shared_model)\n",
        "            self.act_model.add(self.private_act_model)\n",
        "\n",
        "        if os.path.exists(\"/content/drive/Othercomputers/我的笔记本电脑/share/move_part.h5\"):\n",
        "            print(\"load move model\")\n",
        "            self.move_model = models.Sequential()\n",
        "            self.private_move_model = load_model(\"/content/drive/Othercomputers/我的笔记本电脑/share/move_part.h5\", custom_objects={'BasicBlock': BasicBlock})\n",
        "            # self.move_model.add(self.shared_model)\n",
        "            self.move_model.add(self.private_move_model)\n",
        "\n",
        "    def load_target_model(self):\n",
        "        if os.path.exists(\"/content/drive/Othercomputers/我的笔记本电脑/share/act_part.h5\"):\n",
        "            self.target_act_model = load_model(\"/content/drive/Othercomputers/我的笔记本电脑/share/act_part.h5\", custom_objects={'BasicBlock': BasicBlock})\n",
        "        if os.path.exists(\"/content/drive/Othercomputers/我的笔记本电脑/share/move_part.h5\"):\n",
        "            self.target_move_model = load_model(\"/content/drive/Othercomputers/我的笔记本电脑/share/move_part.h5\", custom_objects={'BasicBlock': BasicBlock})\n",
        "\n",
        "    def save_mode(self):\n",
        "        print(\"save model\")\n",
        "        self.private_act_model.save(\"/content/drive/Othercomputers/我的笔记本电脑/share/act_part.h5\")\n",
        "        self.private_move_model.save(\"/content/drive/Othercomputers/我的笔记本电脑/share/move_part.h5\")\n",
        "\n",
        "    def build_resblock(self, filter_num, blocks, name=\"Resnet\", stride=1):\n",
        "        res_blocks = models.Sequential()\n",
        "        # may down sample\n",
        "        res_blocks.add(BasicBlock(filter_num, name + '_1', stride))\n",
        "        # just down sample one time\n",
        "        for pre in range(1, blocks):\n",
        "            res_blocks.add(BasicBlock(filter_num, name + '_2', stride=1))\n",
        "        return res_blocks\n",
        "\n",
        "    # use two groups of net, one for action, one for move\n",
        "    def _build_model(self):\n",
        "\n",
        "        # ------------------ build evaluate_net ------------------\n",
        "\n",
        "        # self.shared_model = models.Sequential()\n",
        "        # self.private_act_model = models.Sequential()\n",
        "        # self.private_move_model = models.Sequential()\n",
        "\n",
        "        # shared part\n",
        "        # pre-process block\n",
        "        # self.shared_model.add(Conv2D(64, (2,3,3),strides=(1,2,2), input_shape=self.input_shape, name='conv1'))\n",
        "        # # self.shared_model.add(BatchNormalization(name='b1'))\n",
        "        # self.shared_model.add(Activation('relu'))\n",
        "        # self.shared_model.add(MaxPooling3D(pool_size=(2,2,2), strides=1, padding=\"VALID\", name='p1'))\n",
        "\n",
        "        # # resnet blocks\n",
        "        # self.shared_model.add(self.build_resblock(64, 2, name='Resnet_1'))\n",
        "        # self.shared_model.add(self.build_resblock(80, 2, name='Resnet_2', stride=2))\n",
        "        # self.shared_model.add(self.build_resblock(128, 2, name='Resnet_3', stride=2))\n",
        "\n",
        "        # output layer for action model\n",
        "        inputs = Input(shape=self.input_shape)\n",
        "        x = Conv3D(32, (2, 3, 3), strides=(1, 2, 2), input_shape=self.input_shape, name='conv1', activation='relu')(\n",
        "            inputs)\n",
        "        x = Conv3D(48, (2, 3, 3), strides=(1, 1, 1), input_shape=self.input_shape, name='conv2', activation='relu')(x)\n",
        "        x = Conv3D(64, (2, 3, 3), strides=(1, 1, 1), input_shape=self.input_shape, name='conv3', activation='relu')(x)\n",
        "        x = Lambda(lambda x: tf.reduce_sum(x, 1))(x)\n",
        "        x = self.build_resblock(64, 2, name='Resnet_1')(x)\n",
        "        x = self.build_resblock(96, 2, name='Resnet_2', stride=2)(x)\n",
        "        x = self.build_resblock(128, 2, name='Resnet_3', stride=2)(x)\n",
        "        x = self.build_resblock(256, 2, name='Resnet_4', stride=2)(x)\n",
        "        x = GlobalAveragePooling2D(name='pooling')(x)\n",
        "        v_func = Dense(1, name='v_func')(x)\n",
        "        a_func = Dense(self.act_dim, name='a_func')(x)\n",
        "        a_func = add([a_func, -tf.reduce_mean(a_func, keepdims=True)])\n",
        "        outputs = add([v_func, a_func])\n",
        "        self.private_act_model = mod(inputs=inputs, outputs=outputs)\n",
        "\n",
        "        # self.private_act_model.add(Reshape((1, -1)))\n",
        "        # self.private_act_model.add(CuDNNLSTM(32))\n",
        "        # self.private_act_model.add(Dense(self.act_dim, name=\"d1\"))        # action model\n",
        "        self.private_act_model.summary()\n",
        "        self.act_model = models.Sequential()\n",
        "        # self.act_model.add(self.shared_model)\n",
        "        self.act_model.add(self.private_act_model)\n",
        "\n",
        "        #target_act_model\n",
        "        input = Input(shape=self.input_shape)\n",
        "        y = Conv3D(32, (2, 3, 3), strides=(1, 2, 2), input_shape=self.input_shape, name='conv1', activation='relu')(\n",
        "            input)\n",
        "        y = Conv3D(48, (2, 3, 3), strides=(1, 1, 1), input_shape=self.input_shape, name='conv2', activation='relu')(y)\n",
        "        y = Conv3D(64, (2, 3, 3), strides=(1, 1, 1), input_shape=self.input_shape, name='conv3', activation='relu')(y)\n",
        "        y = Lambda(lambda x: tf.reduce_sum(x, 1))(y)\n",
        "        y = self.build_resblock(64, 2, name='Resnet_1')(y)\n",
        "        y = self.build_resblock(96, 2, name='Resnet_2', stride=2)(y)\n",
        "        y = self.build_resblock(128, 2, name='Resnet_3', stride=2)(y)\n",
        "        y = self.build_resblock(256, 2, name='Resnet_4', stride=2)(y)\n",
        "        y = GlobalAveragePooling2D(name='pooling')(y)\n",
        "        v = Dense(1, name='v_func')(y)\n",
        "        a = Dense(self.act_dim, name='a_func')(y)\n",
        "        a = add([a, -tf.reduce_mean(a, keepdims=True)])\n",
        "        output = add([v, a])\n",
        "        self.target_act_model = mod(inputs=input, outputs=output)\n",
        "\n",
        "        # output layer for move model\n",
        "        _inputs = Input(shape=self.input_shape)\n",
        "        _x = Conv3D(32, (2, 3, 3), strides=(1, 2, 2), input_shape=self.input_shape, name='conv1', activation='relu')(\n",
        "            _inputs)\n",
        "        _x = Conv3D(48, (2, 3, 3), strides=(1, 1, 1), input_shape=self.input_shape, name='conv2', activation='relu')(_x)\n",
        "        _x = Conv3D(64, (2, 3, 3), strides=(1, 1, 1), input_shape=self.input_shape, name='conv3', activation='relu')(_x)\n",
        "        _x = Lambda(lambda x: tf.reduce_sum(x, 1))(_x)\n",
        "        _x = self.build_resblock(64, 2, name='Resnet_1')(_x)\n",
        "        _x = self.build_resblock(96, 2, name='Resnet_2', stride=2)(_x)\n",
        "        _x = self.build_resblock(128, 2, name='Resnet_3', stride=2)(_x)\n",
        "        _x = self.build_resblock(256, 2, name='Resnet_4', stride=2)(_x)\n",
        "        _x = GlobalAveragePooling2D(name='pooling')(_x)\n",
        "        _v_func = Dense(1, name='v_func')(_x)\n",
        "        _a_func = Dense(self.move_dim, name='a_func')(_x)\n",
        "        _a_func = add([_a_func, -tf.reduce_mean(_a_func, keepdims=True)])\n",
        "        _outputs = add([_v_func, _a_func])\n",
        "        self.private_move_model = mod(inputs=_inputs, outputs=_outputs)\n",
        "\n",
        "        # movement model\n",
        "        self.move_model = models.Sequential()\n",
        "        # self.move_model.add(self.shared_model)\n",
        "        self.move_model.add(self.private_move_model)\n",
        "\n",
        "        # target_move_model\n",
        "        _input = Input(shape=self.input_shape)\n",
        "        _y = Conv3D(32, (2, 3, 3), strides=(1, 2, 2), input_shape=self.input_shape, name='conv1', activation='relu')(\n",
        "            _input)\n",
        "        _y = Conv3D(48, (2, 3, 3), strides=(1, 1, 1), input_shape=self.input_shape, name='conv2', activation='relu')(_y)\n",
        "        _y = Conv3D(64, (2, 3, 3), strides=(1, 1, 1), input_shape=self.input_shape, name='conv3', activation='relu')(_y)\n",
        "        _y = Lambda(lambda x: tf.reduce_sum(x, 1))(_y)\n",
        "        _y = self.build_resblock(64, 2, name='Resnet_1')(_y)\n",
        "        _y = self.build_resblock(96, 2, name='Resnet_2', stride=2)(_y)\n",
        "        _y = self.build_resblock(128, 2, name='Resnet_3', stride=2)(_y)\n",
        "        _y = self.build_resblock(256, 2, name='Resnet_4', stride=2)(_y)\n",
        "        _y = GlobalAveragePooling2D(name='pooling')(_y)\n",
        "        _v = Dense(1, name='v_func')(_y)\n",
        "        _a = Dense(self.move_dim, name='a_func')(_y)\n",
        "        _a = add([_a, -tf.reduce_mean(_a, keepdims=True)])\n",
        "        _output = add([_v, _a])\n",
        "        self.target_act_model = mod(inputs=_input, outputs=_output)\n",
        "\n",
        "    #     # ------------------ build target_model ------------------\n",
        "    #    # shared part\n",
        "\n",
        "    #     self.shared_target_model = models.Sequential()\n",
        "    #     # pre-process block\n",
        "    #     self.shared_target_model.add(Conv3D(64, (2,3,3),strides=(1,2,2), input_shape=self.input_shape, name='conv1'))\n",
        "    #     self.shared_target_model.add(BatchNormalization(name='b1'))\n",
        "    #     self.shared_target_model.add(Activation('relu'))\n",
        "    #     self.shared_target_model.add(MaxPooling3D(pool_size=(2,2,2), strides=1, padding=\"VALID\", name='p1'))\n",
        "\n",
        "    #     # resnet blocks\n",
        "    #     self.shared_target_model.add(self.build_resblock(64, 2, name='Resnet_1'))\n",
        "    #     self.shared_target_model.add(self.build_resblock(80, 2, name='Resnet_2', stride=2))\n",
        "    #     self.shared_target_model.add(self.build_resblock(128, 2, name='Resnet_3', stride=2))\n",
        "\n",
        "    #     # output layer for action model\n",
        "    #     self.private_act_target_model = models.Sequential()\n",
        "    #     self.private_act_target_model.add(self.build_resblock(200, 2, name='Resnet_4', stride=2))\n",
        "    #     self.private_act_target_model.add(GlobalAveragePooling3D())\n",
        "    #     # self.private_act_target_model.add(Reshape((1, -1)))\n",
        "    #     # self.private_act_target_model.add(CuDNNLSTM(32))\n",
        "    #     self.private_act_target_model.add(Dense(self.act_dim, name=\"d1\", kernel_regularizer=regularizers.L2(0.001)))\n",
        "\n",
        "    #     # action model\n",
        "    #     self.act_target_model = models.Sequential()\n",
        "    #     self.act_target_model.add(self.shared_target_model)\n",
        "    #     self.act_target_model.add(self.private_act_target_model)\n",
        "\n",
        "    #     # output layer for move model\n",
        "    #     self.private_move_target_model = models.Sequential()\n",
        "    #     self.private_move_target_model.add(self.build_resblock(200, 2, name='Resnet_4', stride=2))\n",
        "    #     self.private_move_target_model.add(GlobalAveragePooling3D())\n",
        "    #     # self.private_move_target_model.add(Reshape((1, -1)))\n",
        "    #     # self.private_move_target_model.add(CuDNNLSTM(32))\n",
        "    #     self.private_move_target_model.add(Dense(4, name=\"d1\", kernel_regularizer=regularizers.L2(0.001)))\n",
        "\n",
        "    #     # action model\n",
        "    #     self.move_target_model = models.Sequential()\n",
        "    #     self.move_target_model.add(self.shared_target_model)\n",
        "    #     self.move_target_model.add(self.private_move_target_model)\n",
        "\n",
        "    def predict(self, input):\n",
        "\n",
        "        input = tf.expand_dims(input, axis=0)\n",
        "        # shard_output = self.shared_model.predict(input)\n",
        "        pred_move = self.private_move_model(input)\n",
        "        pred_act = self.private_act_model(input)\n",
        "        return pred_move, pred_act\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class DQN:\n",
        "    def __init__(self, model, gamma=0.9, learnging_rate=0.0001):\n",
        "        self.model = model\n",
        "        self.act_dim = model.act_dim\n",
        "        self.act_model = model.act_model\n",
        "        self.move_model = model.move_model\n",
        "        self.gamma = gamma\n",
        "        self.lr = learnging_rate\n",
        "        # --------------------------训练模型--------------------------- # \n",
        "        self.act_model.optimizer = tf.optimizers.Adam(learning_rate=self.lr)\n",
        "        self.act_model.loss_func = tf.losses.MeanSquaredError()\n",
        "\n",
        "        self.move_model.optimizer = tf.optimizers.Adam(learning_rate=self.lr)\n",
        "        self.move_model.loss_func = tf.losses.MeanSquaredError()\n",
        "        # self.act_model.train_loss = tf.metrics.Mean(name=\"train_loss\")\n",
        "        # ------------------------------------------------------------ #\n",
        "        self.act_global_step = 0\n",
        "        self.move_global_step = 0\n",
        "        self.update_target_steps = 100  # 每隔200个training steps再把model的参数复制到target_model中\n",
        "\n",
        "    # train functions for act model\n",
        "    def act_predict(self, obs):\n",
        "        \"\"\" 使用self.act_model的value网络来获取 [Q(s,a1),Q(s,a2),...]\n",
        "        \"\"\"\n",
        "        return self.act_model.predict(obs)\n",
        "\n",
        "    def act_train_step(self, action, features, next_features, labels):\n",
        "        \"\"\" 训练步骤\n",
        "        \"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            # 计算 Q(s,a) 与 target_Q的均方差，得到loss\n",
        "            predictions = self.act_model(features, training=True)\n",
        "            next_pred = self.act_model(next_features, training=True)\n",
        "            best_a = []\n",
        "            for i in range(next_pred.shape[0]):\n",
        "                best_a.append(np.argmax(next_pred[i, :]))\n",
        "            target_q = []\n",
        "            target_pred = self.model.target_act_model(next_features, training=False)\n",
        "            for i in range(next_pred.shape[0]):\n",
        "                target_q.append(target_pred[i, best_a[i]])\n",
        "            target_q = tf.convert_to_tensor(target_q)\n",
        "            enum_action = list(enumerate(action))\n",
        "            pred_action_value = tf.gather_nd(predictions, indices=enum_action)\n",
        "            loss = self.act_model.loss_func(labels + self.gamma * target_q, pred_action_value)\n",
        "        gradients = tape.gradient(loss, self.act_model.trainable_variables)\n",
        "        self.act_model.optimizer.apply_gradients(zip(gradients, self.act_model.trainable_variables))\n",
        "        self.model.act_loss.append(loss)\n",
        "        return np.mean(target_q), tf.reduce_mean(loss, keepdims=False)\n",
        "        # self.act_model.train_loss.update_state(loss)\n",
        "\n",
        "    def act_train_model(self, action, features, next_features, labels, epochs=1):\n",
        "        \"\"\" 训练模型\n",
        "        \"\"\"\n",
        "        q_sum = 0\n",
        "        loss_sum = 0\n",
        "        for epoch in tf.range(1, epochs + 1):\n",
        "            q, loss = self.act_train_step(action, features, next_features, labels)\n",
        "            q_sum = q_sum + q\n",
        "            loss_sum = loss_sum + loss\n",
        "        return q_sum/epochs, loss_sum/epochs\n",
        "    def act_learn(self, obs, action, reward, next_obs, terminal):\n",
        "        \"\"\" 使用DQN算法更新self.act_model的value网络\n",
        "        \"\"\"\n",
        "        # print('learning')\n",
        "        # 每隔200个training steps同步一次model和target_model的参数\n",
        "        # if self.act_global_step % self.update_target_steps == 0:\n",
        "        #     self.act_replace_target()\n",
        "\n",
        "        # 从target_model中获取 max Q' 的值，用于计算target_Q\n",
        "\n",
        "        q, loss = self.act_train_model(action, obs, next_obs, reward, epochs=1)\n",
        "        self.act_global_step += 1\n",
        "        return q, loss\n",
        "        # print('finish')\n",
        "\n",
        "    def act_replace_target(self):  # ???\n",
        "        '''预测模型权重更新到target模型权重'''\n",
        "        for i, l in enumerate(\n",
        "                self.act_target_model.get_layer(index=1).get_layer(index=0).get_layer(index=0).get_layers()):\n",
        "            l.set_weights(self.act_model.get_layer(index=1).get_layer(index=0).get_layer(index=0).get_layer(\n",
        "                index=i).get_weights())\n",
        "        for i, l in enumerate(\n",
        "                self.act_target_model.get_layer(index=1).get_layer(index=0).get_layer(index=1).get_layers()):\n",
        "            l.set_weights(self.act_model.get_layer(index=1).get_layer(index=0).get_layer(index=1).get_layer(\n",
        "                index=i).get_weights())\n",
        "\n",
        "        # for i, l in enumerate(self.act_target_model.get_layer(index=1).get_layer(index=1).get_layer(index=0).get_layers()):\n",
        "        #     l.set_weights(self.act_model.get_layer(index=1).get_layer(index=1).get_layer(index=0).get_layer(index=i).get_weights())\n",
        "        # for i, l in enumerate(self.act_target_model.get_layer(index=1).get_layer(index=1).get_layer(index=1).get_layers()):\n",
        "        #     l.set_weights(self.act_model.get_layer(index=1).get_layer(index=1).get_layer(index=1).get_layer(index=i).get_weights())\n",
        "\n",
        "        # for i, l in enumerate(self.act_target_model.get_layer(index=1).get_layer(index=2).get_layer(index=0).get_layers()):\n",
        "        #     l.set_weights(self.act_model.get_layer(index=1).get_layer(index=2).get_layer(index=0).get_layer(index=i).get_weights())\n",
        "        # for i, l in enumerate(self.act_target_model.get_layer(index=1).get_layer(index=2).get_layer(index=1).get_layers()):\n",
        "        #     l.set_weights(self.act_model.get_layer(index=1).get_layer(index=2).get_layer(index=1).get_layer(index=i).get_weights())\n",
        "\n",
        "        self.act_target_model.get_layer(index=1).get_layer(index=2).set_weights(\n",
        "            self.act_model.get_layer(index=1).get_layer(index=2).get_weights())\n",
        "\n",
        "        # self.act_target_model.get_layer(index=1).get_layer(index=6).set_weights(self.act_model.get_layer(index=1).get_layer(index=6).get_weights())\n",
        "\n",
        "    # train functions for move_model\n",
        "\n",
        "    def move_predict(self, obs):\n",
        "        \"\"\" 使用self.move_model的value网络来获取 [Q(s,a1),Q(s,a2),...]\n",
        "        \"\"\"\n",
        "        return self.move_model.predict(obs)\n",
        "\n",
        "    def move_train_step(self, action, features, next_features, labels):\n",
        "        \"\"\" 训练步骤\n",
        "        \"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            # 计算 Q(s,a) 与 target_Q的均方差，得到loss\n",
        "            predictions = self.move_model(features, training=True)\n",
        "            next_pred = self.move_model(next_features, training=True)\n",
        "            best_a = []\n",
        "            for i in range(next_pred.shape[0]):\n",
        "                best_a.append(np.argmax(next_pred[i, :]))\n",
        "            target_q = []\n",
        "            target_pred = self.model.target_move_model(next_features, training=False)\n",
        "            for i in range(next_pred.shape[0]):\n",
        "                target_q.append(target_pred[i, best_a[i]])\n",
        "            target_q = tf.convert_to_tensor(target_q)\n",
        "            enum_action = list(enumerate(action))\n",
        "            pred_action_value = tf.gather_nd(predictions, indices=enum_action)\n",
        "            loss = self.move_model.loss_func(labels + self.gamma * target_q, pred_action_value)\n",
        "            if loss > 10e+8:\n",
        "              loss = 10e+8\n",
        "        gradients = tape.gradient(loss, self.move_model.trainable_variables)\n",
        "        self.move_model.optimizer.apply_gradients(zip(gradients, self.move_model.trainable_variables))\n",
        "        self.model.move_loss.append(loss)\n",
        "        return np.mean(target_q), tf.reduce_mean(loss, keepdims=False)\n",
        "        # self.move_plot_loss()\n",
        "        # print(\"Move loss: \", loss)\n",
        "        # self.move_model.train_loss.update_state(loss)\n",
        "\n",
        "    def move_train_model(self, action, features, next_features, labels, epochs=1):\n",
        "        \"\"\" 训练模型\n",
        "        \"\"\"\n",
        "        q_sum = 0\n",
        "        loss_sum = 0\n",
        "        for epoch in tf.range(1, epochs + 1):\n",
        "            q, loss = self.move_train_step(action, features, next_features, labels)\n",
        "            q_sum = q_sum + q\n",
        "            loss_sum = loss_sum +loss\n",
        "        return q_sum/epochs, loss_sum/epochs\n",
        "\n",
        "    def move_learn(self, obs, action, reward, next_obs, terminal):\n",
        "        \"\"\" 使用DQN算法更新self.move_model的value网络\n",
        "        \"\"\"\n",
        "        q, loss = self.move_train_model(action, obs, next_obs, reward, epochs=1)\n",
        "        self.move_global_step += 1\n",
        "        return q, loss\n",
        "\n",
        "    def move_replace_target(self):\n",
        "        '''预测模型权重更新到target模型权重'''\n",
        "\n",
        "        for i, l in enumerate(\n",
        "                self.move_target_model.get_layer(index=1).get_layer(index=0).get_layer(index=0).get_layers()):\n",
        "            l.set_weights(self.move_model.get_layer(index=1).get_layer(index=0).get_layer(index=0).get_layer(\n",
        "                index=i).get_weights())\n",
        "        for i, l in enumerate(\n",
        "                self.move_target_model.get_layer(index=1).get_layer(index=0).get_layer(index=1).get_layers()):\n",
        "            l.set_weights(self.move_model.get_layer(index=1).get_layer(index=0).get_layer(index=1).get_layer(\n",
        "                index=i).get_weights())\n",
        "\n",
        "        # for i, l in enumerate(self.move_target_model.get_layer(index=1).get_layer(index=1).get_layer(index=0).get_layers()):\n",
        "        #     l.set_weights(self.move_model.get_layer(index=1).get_layer(index=1).get_layer(index=0).get_layer(index=i).get_weights())\n",
        "        # for i, l in enumerate(self.move_target_model.get_layer(index=1).get_layer(index=1).get_layer(index=1).get_layers()):\n",
        "        #     l.set_weights(self.move_model.get_layer(index=1).get_layer(index=1).get_layer(index=1).get_layer(index=i).get_weights())\n",
        "\n",
        "        # for i, l in enumerate(self.move_target_model.get_layer(index=1).get_layer(index=2).get_layer(index=0).get_layers()):\n",
        "        #     l.set_weights(self.move_model.get_layer(index=1).get_layer(index=2).get_layer(index=0).get_layer(index=i).get_weights())\n",
        "        # for i, l in enumerate(self.move_target_model.get_layer(index=1).get_layer(index=2).get_layer(index=1).get_layers()):\n",
        "        #     l.set_weights(self.move_model.get_layer(index=1).get_layer(index=2).get_layer(index=1).get_layer(index=i).get_weights())\n",
        "\n",
        "        self.move_target_model.get_layer(index=1).get_layer(index=2).set_weights(\n",
        "            self.move_model.get_layer(index=1).get_layer(index=2).get_weights())\n",
        "\n",
        "        # self.move_target_model.get_layer(index=1).get_layer(index=6).set_weights(self.move_model.get_layer(index=1).get_layer(index=6).get_weights())\n",
        "\n",
        "    def replace_target(self):\n",
        "        # print(\"replace target\")\n",
        "\n",
        "        # copy conv3d_1\n",
        "        self.model.shared_target_model.get_layer(index=0).set_weights(\n",
        "            self.model.shared_model.get_layer(index=0).get_weights())\n",
        "        # copy batchnormalization_1\n",
        "        self.model.shared_target_model.get_layer(index=1).set_weights(\n",
        "            self.model.shared_model.get_layer(index=1).get_weights())\n",
        "\n",
        "        # copy shard_resnet block\n",
        "        for i, l in enumerate(self.model.shared_target_model.get_layer(index=4).get_layer(index=0).get_layers()):\n",
        "            l.set_weights(\n",
        "                self.model.shared_model.get_layer(index=4).get_layer(index=0).get_layer(index=i).get_weights())\n",
        "        for i, l in enumerate(self.model.shared_target_model.get_layer(index=4).get_layer(index=1).get_layers()):\n",
        "            l.set_weights(\n",
        "                self.model.shared_model.get_layer(index=4).get_layer(index=1).get_layer(index=i).get_weights())\n",
        "\n",
        "        for i, l in enumerate(self.model.shared_target_model.get_layer(index=5).get_layer(index=0).get_layers()):\n",
        "            l.set_weights(\n",
        "                self.model.shared_model.get_layer(index=5).get_layer(index=0).get_layer(index=i).get_weights())\n",
        "        for i, l in enumerate(self.model.shared_target_model.get_layer(index=5).get_layer(index=1).get_layers()):\n",
        "            l.set_weights(\n",
        "                self.model.shared_model.get_layer(index=5).get_layer(index=1).get_layer(index=i).get_weights())\n",
        "\n",
        "        self.move_replace_target()\n",
        "        self.act_replace_target()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "HollowKnight_Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}